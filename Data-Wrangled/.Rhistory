library(tidyverse)
library(survey)
library(glmnet)
library(latex2exp)
library(jtools)
library(weights)
setwd("/Volumes/My Passport for Mac/Arthur Lab/FPED Raw Data/Analysis files/GitHub Repository Files /NHANES-Diet-Penalized-Regression/Data-Wrangled")
xdata<-readRDS("03-Inclusions-Exclusions.rds")
# collapse red mt and organ mt to same group give very low intake of organ mts
xdata$Meat<-xdata$RedMts + xdata$OrganMts
# copy
x.data <- xdata
####################################################################################################
############################ Dietary Patterns Extraction: Elastic Net ##############################
####################################################################################################
## write function to do the extraction and produce plots of
## subset data matrix for elastic net procedure using cases that met inclusion/exlusion criteria##
caonly<-x.data[which(x.data$Diet.ext.ind.reg==1),]
caonly<-caonly%>%
mutate(FoodAsstPnowic=ifelse(FoodAsstPnowic=="yes",1,
ifelse(FoodAsstPnowic=="no",0,NA)))%>%
mutate(Agecat=ifelse(Agecat=="elderly",1,
ifelse(Agecat=="non-elderly",0,NA)))%>%
mutate(BinFSH=ifelse(BinFoodSecHH=="Low",1,
ifelse(BinFoodSecHH=="High",0,NA)))%>%
mutate(HHSize_bin=ifelse(HHSize>=5,1,
ifelse(HHSize<5,0,NA)))
fdgrp.columns<-which(colnames(caonly) %in% c("ProcessedMts","Meat","Poultry","Fish_Hi","Fish_Lo",
"Eggs","SolidFats","Oils","Milk","Yogurt","Cheese",
"Alcohol","FruitOther","F_CitMelBer","Tomatoes",
"GreenLeafy","DarkYlVeg","OtherVeg",
"Potatoes","OtherStarchyVeg","Legumes","Soy","RefinedGrain",
"WholeGrain","Nuts","AddedSugars"))
fdgrp.columns<-fdgrp.columns[c(1,26,2:25)] # re-arrange so that Meat column index is second column index
fs.outcome.column<-which(colnames(caonly)=="BinFSH")
fdas.outcome.column<-which(colnames(caonly)=="FoodAsstPnowic")
age.outcome.column<-which(colnames(caonly)=="Agecat")
hhsize.outcome.column<-which(colnames(caonly)=="HHSize_bin")
weight.column<-which(colnames(caonly)=="WTDR18YR")
kcal.column<-which(colnames(caonly)=="KCAL")
seqn.column<-which(colnames(caonly)=="SEQN")
# divide by total energy intake for multivariate density approach to energy adjustment
for (j in fdgrp.columns){#ensure proper variables are indicated by the column index in this line of code before proceeding
caonly[,j]<-caonly[,j]/caonly[,kcal.column]
}
# center and scale food group variables before regressions
for (j in fdgrp.columns){#ensure proper variables are indicated by the column index in this line of code before proceeding
caonly[,j]<-(caonly[,j]-mean(caonly[,j],na.rm=T))/sd(caonly[,j],na.rm = T)
}
# FS outcome
par(mfrow=c(2,2),mar=c(3,3,2,1))
mat<-na.omit(as.matrix(caonly[,c(fdgrp.columns,fs.outcome.column,weight.column)]))
xmat<-mat[,1:26] # food grps
yvec<-mat[,27] # binary response
xwts<-mat[,28]/mean(mat[,28]) # normalize weights
library(caret)
lambda.grid <- seq(0, 0.01, length=10)
alpha.grid <- seq(0, 1, 0.1)
train.grid <- expand.grid(.lambda = lambda.grid,.alpha = alpha.grid)
ctrl    <- trainControl(method = "repeatedcv",
number = 5,
repeats = 5,
savePredictions = TRUE,
verboseIter = T)
mod_fit <- train(y= factor(yvec),
x=xmat,
tuneGrid = train.grid,
method = "glmnet",
family="binomial",
trControl = ctrl,
weights = xwts,
type.measure='auc')
mod_fit$bestTune
coef(mod_fit$finalModel, mod_fit$bestTune$lambda )
lambda.grid <- seq(0, 1, length=10)
alpha.grid <- seq(0, 1, 0.1)
train.grid <- expand.grid(.lambda = lambda.grid,.alpha = alpha.grid)
ctrl    <- trainControl(method = "repeatedcv",
number = 5,
repeats = 5,
savePredictions = TRUE,
verboseIter = T)
mod_fit <- train(y= factor(yvec),
x=xmat,
tuneGrid = train.grid,
method = "glmnet",
family="binomial",
trControl = ctrl,
weights = xwts,
type.measure='auc')
mod_fit$bestTune
coef(mod_fit$finalModel, mod_fit$bestTune$lambda )
coef(mod_fit$finalModel, mod_fit$bestTune$alpha )
coef(mod_fit$finalModel, mod_fit$bestTune$lambdaOpt )
library(glmnetUtils)
cva.glmnet()
mod_fit<-cva.glmnet(y= factor(yvec),
x=xmat,
alpha = seq(0, 1, 0.1),
family="binomial", weights = xwts)
mod_fit$alpha
mod_fit$modlist
glmnet:::coef.cv.glmnet(mod_list)
glmnet:::coef.cv.glmnet(mod_fit)
coef(mod_fit, s = "lambda.min")
coef(mod_fit, alpha=get_alpha(mod_fit))
# Get alpha.
get_alpha <- function(fit) {
alpha <- fit$alpha
error <- sapply(fit$modlist, function(mod) {min(mod$cvm)})
alpha[which.min(error)]
}
coef(mod_fit, alpha=get_alpha(mod_fit))
lambda.grid <- seq(0, 1000, length=10)
alpha.grid <- seq(0, 1, 0.1)
train.grid <- expand.grid(.lambda = lambda.grid,.alpha = alpha.grid)
ctrl    <- trainControl(method = "repeatedcv",
number = 5,
repeats = 5,
savePredictions = TRUE,
verboseIter = T)
mod_fit <- train(y= factor(yvec),
x=xmat,
tuneGrid = train.grid,
method = "glmnet",
family="binomial",
trControl = ctrl,
weights = xwts,
type.measure='auc')
coef(mod_fit$finalModel, mod_fit$bestTune$alpha )
mod_fit <- train(y= factor(yvec),
x=xmat,
tuneGrid = train.grid,
method = "glmnet",
family="binomial",
trControl = ctrl,
weights = xwts)
mod_fit$results
mod_fit <- train(y= factor(yvec),
x=xmat,
tuneGrid = train.grid,
method = "glmnet",
family="binomial",
trControl = ctrl)
mod_fit$results
mod_fit$bestTune
mod_fit$control
mod_fit$preProcess
names(caonly)
paste(names(caonly)[72,110,75:98], collapse='+')
paste(names(caonly)[c(72,110,75:98)], collapse='+')
class(caonly$BinFSH
class(caonly$BinFSH)
class(caonly$BinFoodSecHH)
mod_fit <- train(BinFoodSecHH~ProcessedMts+Meat+Poultry+Fish_Hi+Fish_Lo+Eggs+SolidFats+Oils+Milk+Yogurt+
Cheese+Alcohol+FruitOther+F_CitMelBer+Tomatoes+GreenLeafy+DarkYlVeg+
OtherVeg+Potatoes+OtherStarchyVeg+Legumes+Soy+RefinedGrain+WholeGrain+Nuts+AddedSugars,
data=caonly,
tuneGrid = train.grid,
method = "glmnet",
family="binomial",
trControl = ctrl)
coef(mod_fit$finalModel, mod_fit$bestTune$alpha )
mod_fit$results
library(glmnet)
library(caret)
data(BinomialExample)
y[y==0] = "low"
y[y==1] = "high"
y <- as.factor(y)
set.seed(1)
splitSample <- createDataPartition(y, p = 0.8, list = FALSE)
training_expression <- x[splitSample,]
training_phenotype <- y[splitSample]
validation_expression <- x[-splitSample,]
validation_phenotype <- y[-splitSample]
eGrid <- expand.grid(.alpha=seq(0.1,0.9, by=0.1),.lambda=seq(0,1,by=0.01))
Control <- trainControl(verboseIter=TRUE, classProbs=TRUE, summaryFunction=twoClassSummary, method="cv")
eGrid
Control <- trainControl(verboseIter=TRUE, classProbs=TRUE, summaryFunction=twoClassSummary, method="cv")
set.seed(1)
netFit <- train(x = training_expression, y = training_phenotype,method = "glmnet", metric = "ROC", tuneGrid=eGrid,trControl = Control)
x[splitSample,]
training_expression <- as.matrix(x[splitSample,])
validation_phenotype <- as.matrix(y[-splitSample])
netFit <- train(x = training_expression, y = training_phenotype,method = "glmnet", metric = "ROC", tuneGrid=eGrid,trControl = Control)
ctrl    <- trainControl(method = "repeatedcv",
number = 5,
repeats = 5,
verboseIter=TRUE, classProbs=TRUE, summaryFunction=twoClassSummary))
ctrl    <- trainControl(method = "repeatedcv",
number = 5,
repeats = 5,
verboseIter=TRUE, classProbs=TRUE, summaryFunction=twoClassSummary)
mod_fit <- train(y= factor(yvec),
x=xmat,
tuneGrid = train.grid,
method = "glmnet",
family="binomial",
trControl = ctrl)
## subset data matrix for elastic net procedure using cases that met inclusion/exlusion criteria##
caonly<-x.data[which(x.data$Diet.ext.ind.reg==1),]
caonly<-caonly%>%
mutate(FoodAsstPnowic=ifelse(FoodAsstPnowic=="yes",1,
ifelse(FoodAsstPnowic=="no",0,NA)))%>%
mutate(Agecat=ifelse(Agecat=="elderly",1,
ifelse(Agecat=="non-elderly",0,NA)))%>%
mutate(BinFSH=ifelse(BinFoodSecHH=="Low",1,
ifelse(BinFoodSecHH=="High",0,NA)))%>%
mutate(HHSize_bin=ifelse(HHSize>=5,1,
ifelse(HHSize<5,0,NA)))
fdgrp.columns<-which(colnames(caonly) %in% c("ProcessedMts","Meat","Poultry","Fish_Hi","Fish_Lo",
"Eggs","SolidFats","Oils","Milk","Yogurt","Cheese",
"Alcohol","FruitOther","F_CitMelBer","Tomatoes",
"GreenLeafy","DarkYlVeg","OtherVeg",
"Potatoes","OtherStarchyVeg","Legumes","Soy","RefinedGrain",
"WholeGrain","Nuts","AddedSugars"))
fdgrp.columns<-fdgrp.columns[c(1,26,2:25)] # re-arrange so that Meat column index is second column index
fs.outcome.column<-which(colnames(caonly)=="BinFSH")
fdas.outcome.column<-which(colnames(caonly)=="FoodAsstPnowic")
age.outcome.column<-which(colnames(caonly)=="Agecat")
hhsize.outcome.column<-which(colnames(caonly)=="HHSize_bin")
weight.column<-which(colnames(caonly)=="WTDR18YR")
kcal.column<-which(colnames(caonly)=="KCAL")
seqn.column<-which(colnames(caonly)=="SEQN")
# divide by total energy intake for multivariate density approach to energy adjustment
for (j in fdgrp.columns){#ensure proper variables are indicated by the column index in this line of code before proceeding
caonly[,j]<-caonly[,j]/caonly[,kcal.column]
}
# center and scale food group variables before regressions
for (j in fdgrp.columns){#ensure proper variables are indicated by the column index in this line of code before proceeding
caonly[,j]<-(caonly[,j]-mean(caonly[,j],na.rm=T))/sd(caonly[,j],na.rm = T)
}
mat<-na.omit(as.matrix(caonly[,c(fdgrp.columns,fs.outcome.column,weight.column)]))
xmat<-mat[,1:26] # food grps
yvec<-mat[,27] # binary response
xwts<-mat[,28]/mean(mat[,28]) # normalize weights
ctrl    <- trainControl(method = "repeatedcv",
number = 5,
repeats = 5,
verboseIter=TRUE, classProbs=TRUE, summaryFunction=twoClassSummary)
mod_fit <- train(y= factor(yvec),
x=xmat,
tuneGrid = train.grid,
method = "glmnet",
family="binomial",
trControl = ctrl)
lambda.grid <- seq(0, 1000, length=10)
alpha.grid <- seq(0, 10, 0.1)
train.grid <- expand.grid(.lambda = lambda.grid,.alpha = alpha.grid)
ctrl    <- trainControl(method = "repeatedcv",
number = 5,
repeats = 5,
verboseIter=TRUE, classProbs=TRUE, summaryFunction=twoClassSummary)
mod_fit <- train(y= factor(yvec),
x=xmat,
tuneGrid = train.grid,
method = "glmnet",
family="binomial",
trControl = ctrl)
